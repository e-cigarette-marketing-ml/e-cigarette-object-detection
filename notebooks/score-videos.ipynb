{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ffa993-8769-4b77-9111-d14853ce1d1a",
   "metadata": {},
   "source": [
    "# Apply models to new videos\n",
    "\n",
    "Jan. 2023\n",
    "\n",
    "This is derived from video-evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ad8e1a-9e18-410e-ba71-0517646a5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/ck37/projects/ecig-vaping\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pyprojroot\n",
    "dir_proj = pyprojroot.here()\n",
    "print(\"Project directory:\", dir_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f060aba-2bd3-49db-98f8-6b17b828e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video directory: /vape/collection/appended_scrape_download/TikTok/Influencers/tot_coding\n"
     ]
    }
   ],
   "source": [
    "# Video list\n",
    "\n",
    "dir_videos = Path(\"/vape/collection/appended_scrape_download/TikTok/Influencers/tot_coding\")\n",
    "print(\"Video directory:\", dir_videos)\n",
    "\n",
    "# Not using this code currently:\n",
    "\"\"\"\n",
    "# Extract the filenames for the mp4s in our target directory.\n",
    "files_videos = [video.stem for video in dir_videos.glob('**/*.mp4')]\n",
    "print(f\"mp4s found ({len(files_videos)}):\")\n",
    "#print(\", \".join([video for video in files_videos]))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd49aa66-05ae-43b1-b565-2ed814cf8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73fd82f-8cf4-46ea-9782-3f2d13587616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         17361 non-null  int64 \n",
      " 1   infl_username      17361 non-null  object\n",
      " 2   number             17361 non-null  int64 \n",
      " 3   video_path         17361 non-null  object\n",
      " 4   video_shortcode    17361 non-null  object\n",
      " 5   year               17361 non-null  int64 \n",
      " 6   year_recent        17361 non-null  int64 \n",
      " 7   date_tot           17361 non-null  object\n",
      " 8   n_videos_per_infl  17361 non-null  int64 \n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 1.2+ MB\n",
      "   Unnamed: 0 infl_username  number  \\\n",
      "0           1   _auliarmdhn       2   \n",
      "1           2   _auliarmdhn       3   \n",
      "2           3   _auliarmdhn       4   \n",
      "3           4   _auliarmdhn       5   \n",
      "4           5   _auliarmdhn       6   \n",
      "\n",
      "                                          video_path  \\\n",
      "0  /home/juliav/vape/collection/appended_scrape_d...   \n",
      "1  /home/juliav/vape/collection/appended_scrape_d...   \n",
      "2  /home/juliav/vape/collection/appended_scrape_d...   \n",
      "3  /home/juliav/vape/collection/appended_scrape_d...   \n",
      "4  /home/juliav/vape/collection/appended_scrape_d...   \n",
      "\n",
      "                                  video_shortcode  year  year_recent  \\\n",
      "0  _auliarmdhn_1647481644_7075879772068318491.mp4  2022            1   \n",
      "1  _auliarmdhn_1647501606_7075965515939761435.mp4  2022            1   \n",
      "2  _auliarmdhn_1647507501_7075990835371822362.mp4  2022            1   \n",
      "3  _auliarmdhn_1647516486_7076029423501331738.mp4  2022            1   \n",
      "4  _auliarmdhn_1647587115_7076332774206098714.mp4  2022            1   \n",
      "\n",
      "              date_tot  n_videos_per_infl  \n",
      "0  2022-03-16 18:47:24                194  \n",
      "1  2022-03-17 00:20:06                194  \n",
      "2  2022-03-17 01:58:21                194  \n",
      "3  2022-03-17 04:28:06                194  \n",
      "4  2022-03-18 00:05:15                194  \n",
      "/home/juliav/vape/collection/appended_scrape_download/TikTok/Influencers/tot_coding/_auliarmdhn/_auliarmdhn_1647481644_7075879772068318491.mp4\n"
     ]
    }
   ],
   "source": [
    "file_video_list = \"../analytic_sample_17361_20192022.csv\"\n",
    "video_df = pd.read_csv(dir_videos / file_video_list)\n",
    "video_df.info()\n",
    "print(video_df.head())\n",
    "print(video_df.video_path.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8fe3c1-e5d0-4798-aa35-9020454354d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix video paths (or skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f7c33-54f9-4309-9ac1-0bf20665f6b0",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b329ce60-d800-401d-94bc-11f88b4c6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file: /home/ck37/projects/ecig-vaping/models/vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco.py\n",
      "Find model: True\n",
      "Checkpoint file: /home/ck37/projects/ecig-vaping/notebooks/work_dirs/vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco-20220523-105448/latest.pth\n",
      "Find checkpoint: True\n"
     ]
    }
   ],
   "source": [
    "# Copied from mmdet-train.ipynb and video-evaluation.ipynb\n",
    "model_name = \"vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco\"\n",
    "dir_models = dir_proj / \"models\"\n",
    "\n",
    "path_model = dir_models / str(model_name + \".py\")\n",
    "print(\"Model file:\", path_model)\n",
    "print(\"Find model:\", path_model.is_file())\n",
    "timestr = \"20220523-105448\"\n",
    "\n",
    "file_checkpoint = dir_proj / ('notebooks/work_dirs/' + model_name + \"-\" + timestr +'/latest.pth')\n",
    "print(\"Checkpoint file:\", file_checkpoint)\n",
    "print(\"Find checkpoint:\", file_checkpoint.is_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49612005-97c6-45f6-8659-a3d0b75bb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from video-evaluation.ipynb\n",
    "import os\n",
    "\n",
    "def predict_video(video_name, video_dir,\n",
    "                  dir_output = pyprojroot.here() / \"data/detections/videos\",\n",
    "                  box_threshold = 0.4,\n",
    "                  overwrite = False,\n",
    "                  verbose = False):\n",
    "\n",
    "    video_file = video_dir / video_name\n",
    "    \n",
    "    if not os.path.exists(video_file):\n",
    "        print(\"Could not find video file\")\n",
    "        raise Exception\n",
    "    \n",
    "    # This will contain the .mp4 file extension.\n",
    "    path_out = dir_output / Path(video_file).name\n",
    "    \n",
    "    if path_out.is_file() and not overwrite:\n",
    "        print(\"Skipping file - output already exists. \", Path(video_file.name))\n",
    "        return\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Analyzing\", video_name)\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Output path:\", path_out)\n",
    "    \n",
    "    # This will create an output mp4 and an output pkl (to be analyzed).\n",
    "    # Default threshold is 0.3\n",
    "    !python {pyprojroot.here()}/notebooks/video_demo-ck.py \"{video_file}\" \\\n",
    "        {path_model} \\\n",
    "        {file_checkpoint} \\\n",
    "        --out \"{path_out}\" \\\n",
    "        --save_result \\\n",
    "        --score-thr {box_threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd0fad8-ec91-4bf2-9806-935cf8b1e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis output dir: /home/ck37/projects/ecig-vaping/data/detections/analytic_sample_17361_20192022\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "dir_output = pyprojroot.here() / \"data/detections/\" / Path(file_video_list).stem\n",
    "print(\"Analysis output dir:\", dir_output)\n",
    "if not os.path.exists(dir_output):\n",
    "    os.makedirs(dir_output)\n",
    "print(\"Exists:\", os.path.exists(dir_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ed86e12-951d-4e0e-b9bd-37994121b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing single video video.\n",
      "Analyzing several_pods_cropped(1).mp4\n",
      "Output path: /home/ck37/several_pods_cropped(1).mp4\n",
      "Skipping file - output already exists.\n",
      "CPU times: user 419 µs, sys: 220 µs, total: 639 µs\n",
      "Wall time: 521 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if False:\n",
    "\n",
    "    print(f\"Analyzing single video video.\")\n",
    "\n",
    "    video_path = Path(\"/home/ck37/tmp/several_pods_cropped(1).mp4\")\n",
    "    video_name = video_path.name\n",
    "    video_dir = video_path.parent\n",
    "\n",
    "    # Second argument is the probability threshold for showing a bounding box.\n",
    "    predict_video(video_name, video_dir,\n",
    "                  dir_output = Path(\"/home/ck37/\"),\n",
    "                  box_threshold = 0.4, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744eec59-2640-4f0f-b132-a65aca071ac5",
   "metadata": {},
   "source": [
    "### Analyze videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd8977-029a-4879-9921-ab950f7be9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Analyzing {video_df.shape[0]:,} videos.\")\n",
    "for index, row in video_df.iterrows():\n",
    "    print(f\"Video {index}\")\n",
    "    video_path = Path(row['video_path'])\n",
    "    video_name = video_path.name\n",
    "    video_dir = video_path.parent\n",
    "    # TODO: check if video has already been analyzed.\n",
    "    # Second argument is the probability threshold for showing a bounding box.\n",
    "    predict_video(video_name, video_dir, dir_output = dir_output, box_threshold = 0.4, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d6ef9-4663-4503-b1ea-3b3a034c4742",
   "metadata": {},
   "source": [
    "## Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1779f1-b1f1-42a3-ae98-0ec10f7dabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload predicted to Google drive:\n",
    "for video_name in files_videos:\n",
    "    # TO FIX:\n",
    "    # video_file = pyprojroot.here() / \"data/detections/videos\" / (video_name + \".mp4\")\n",
    "    if video_file.is_file():\n",
    "        # TO FIX:\n",
    "        !rclone copy --progress {video_file} gdrive:deep_learning/detections/{Path(file_video_list).stem}\n",
    "    else:\n",
    "        print(\"Could not find prediction video for:\", video_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openmmlab]",
   "language": "python",
   "name": "conda-env-openmmlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
